{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df22f07",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "* R --> Retrievel\n",
    "* A --> Augented\n",
    "* G --> Generation\n",
    "\n",
    "* First the document is stored in vector database.\n",
    "* We take prompt from the user.\n",
    "* Relevant informatoion is **Retrived** from the Vector database on the basis the prompt.\n",
    "* The prompt and the context from the retrieved document is **Augmented**.  \n",
    "* This augmented prompt is used to **Generate** the response from LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sarth\\appdata\\roaming\\python\\python313\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (1.2.7)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.4)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.10.0-cp313-cp313-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.3.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarth\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Downloading faiss_cpu-1.13.2-cp313-cp313-win_amd64.whl (18.9 MB)\n",
      "   ---------------------------------------- 0.0/18.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/18.9 MB 12.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 5.5/18.9 MB 17.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 11.0/18.9 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 16.0/18.9 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.9/18.9 MB 20.9 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 22.4 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 4.7/12.0 MB 22.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.0 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 566.1/566.1 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 22.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading torch-2.10.0-cp313-cp313-win_amd64.whl (113.8 MB)\n",
      "   ---------------------------------------- 0.0/113.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 5.2/113.8 MB 26.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 10.7/113.8 MB 25.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 16.3/113.8 MB 26.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 22.0/113.8 MB 26.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 28.0/113.8 MB 26.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 33.8/113.8 MB 27.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 39.1/113.8 MB 26.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 44.6/113.8 MB 26.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 49.8/113.8 MB 26.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 54.5/113.8 MB 26.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 58.7/113.8 MB 25.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 63.7/113.8 MB 25.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 68.4/113.8 MB 25.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 73.4/113.8 MB 25.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 78.4/113.8 MB 24.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 82.6/113.8 MB 24.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 87.8/113.8 MB 24.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 92.0/113.8 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 97.5/113.8 MB 24.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 102.5/113.8 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 107.5/113.8 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.9/113.8 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.5/113.8 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 113.8/113.8 MB 22.8 MB/s eta 0:00:00\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, typing-inspect, safetensors, requests, marshmallow, httpx-sse, faiss-cpu, torch, huggingface-hub, dataclasses-json, tokenizers, pydantic-settings, transformers, sentence-transformers, langchain-community\n",
      "\n",
      "  Attempting uninstall: requests\n",
      "\n",
      "    Found existing installation: requests 2.32.3\n",
      "\n",
      "   -------- -------------------------------  3/15 [requests]\n",
      "    Uninstalling requests-2.32.3:\n",
      "   -------- -------------------------------  3/15 [requests]\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "   -------- -------------------------------  3/15 [requests]\n",
      "   ---------- -----------------------------  4/15 [marshmallow]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ---------------- -----------------------  6/15 [faiss-cpu]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   ------------------ ---------------------  7/15 [torch]\n",
      "   --------------------- ------------------  8/15 [huggingface-hub]\n",
      "   --------------------- ------------------  8/15 [huggingface-hub]\n",
      "   --------------------- ------------------  8/15 [huggingface-hub]\n",
      "   --------------------- ------------------  8/15 [huggingface-hub]\n",
      "   --------------------- ------------------  8/15 [huggingface-hub]\n",
      "   -------------------------- ------------- 10/15 [tokenizers]\n",
      "  Attempting uninstall: pydantic-settings\n",
      "   -------------------------- ------------- 10/15 [tokenizers]\n",
      "    Found existing installation: pydantic-settings 2.6.1\n",
      "   -------------------------- ------------- 10/15 [tokenizers]\n",
      "    Uninstalling pydantic-settings-2.6.1:\n",
      "   -------------------------- ------------- 10/15 [tokenizers]\n",
      "      Successfully uninstalled pydantic-settings-2.6.1\n",
      "   -------------------------- ------------- 10/15 [tokenizers]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-settings]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   -------------------------------- ------- 12/15 [transformers]\n",
      "   ---------------------------------- ----- 13/15 [sentence-transformers]\n",
      "   ---------------------------------- ----- 13/15 [sentence-transformers]\n",
      "   ---------------------------------- ----- 13/15 [sentence-transformers]\n",
      "   ---------------------------------- ----- 13/15 [sentence-transformers]\n",
      "   ---------------------------------- ----- 13/15 [sentence-transformers]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ------------------------------------- -- 14/15 [langchain-community]\n",
      "   ---------------------------------------- 15/15 [langchain-community]\n",
      "\n",
      "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.2 httpx-sse-0.4.3 huggingface-hub-0.36.0 langchain-community-0.4.1 marshmallow-3.26.2 pydantic-settings-2.12.0 requests-2.32.5 safetensors-0.7.0 sentence-transformers-5.2.0 tokenizers-0.22.2 torch-2.10.0 transformers-4.57.6 typing-inspect-0.9.0 typing-inspection-0.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 6.0.7 requires ipython!=8.17.1,<9.0.0,>=8.13.0; python_version > \"3.8\", but you have ipython 9.5.0 which is incompatible.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "# !pip install faiss-cpu langchain-community sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "513735ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966d8fc",
   "metadata": {},
   "source": [
    "# Step 1 : Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50726f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\AppData\\Local\\Temp\\ipykernel_7328\\1639348513.py:9: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(model_name='all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf5851fe12044c5b1052127ea7061dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sarth\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9ca2174c4d4d6c86cfadbf36b7f9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eb6f213ea841cda4cfc53db8626f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298fdafad0de4b44bb2ab1a4b1473f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7fa027ab824da78a104656c320ab68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b1bb8f37ab4849b34a6e106dbfce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2507e6839c7a4b748af41d5c6771e2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4a42c661394c4e97b4ce97d05b2664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afe145dc9bb42a0adbb44f1ddbba1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f01b9d30f143008cc0609c6ac1fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4fee34d59f423bb1e62323088243b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First lets configure the model\n",
    "\n",
    "# LLM Model\n",
    "gemini_key = os.getenv('Google_api_key1')\n",
    "genai.configure(api_key=gemini_key)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "\n",
    "# Configure Embedding Model\n",
    "embedding_model = HuggingFaceBgeEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394379d1",
   "metadata": {},
   "source": [
    "# Step 2: Get the document and extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9b938f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Lets read the pdf and extract the text from it\n",
    "\n",
    "pdf_file = PdfReader('D:\\GenAI\\RAGBASED_CHATBOT\\RagBasedChatBot\\sample.pdf')\n",
    "\n",
    "raw_text = ''\n",
    "for page in pdf_file.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text = raw_text + text + '\\n'\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6508cc3c",
   "metadata": {},
   "source": [
    "# Step 3: Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9024b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to split the text\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69d4c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5b941f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de5573",
   "metadata": {},
   "source": [
    "# Step 4: Create the Vector Database. (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3e5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_texts(chunks,embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91420231",
   "metadata": {},
   "source": [
    "# Step 5: Get the prompt from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69e4628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Give the 5 line summary of the project.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b0cfc0",
   "metadata": {},
   "source": [
    "# Step 6: Retrieval (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b9d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k':3})\n",
    "retrived_docs = retriever.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c33c7894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='96bd23ad-63ab-4822-8908-4148e83976fd', metadata={}, page_content='Dr.S.Vigneshwari M.E., Ph.D., and Dr.L.Lakshmanan M.E., Ph.D., Heads of the  \\nDepartment of Computer Science and Engineering for providing me necessary \\nsupport and details at the right time during the progressive reviews. \\nI would like to express my sincere and deep sense of gratitude to my Project Guide  Dr. \\nR. AROUL CANESSANE  M.E., Ph.D.,  for her valuable guidance, suggestions and  \\nconstant encouragement paved way for the successful completion of my project work. \\nI wish to express my thanks to all Teaching and Non -teaching staff members of the  \\nDepartment of Computer Science and Engineering who were helpful in many \\nways for the completion of the project.\\n5  \\n \\n                                 TABLE OF CONTENT \\n \\nINDEX \\nNO \\n                                             TITLE PAGE \\nNO \\n1.                                 ABSTRACT 6 \\n2. INTRODUCTION 7 \\n3.                                     AIM 13 \\n4.                                   SCOPE 13'),\n",
       " Document(id='6fc10f4f-bbac-4ddb-a0f9-b17d53578295', metadata={}, page_content='documenting the artifacts of software system, as well as for business modeling and other non -software \\nsystems.  \\nThe UML represents a collection of be st engineering practices that have proven successful in the \\nmodeling of large and complex systems. \\n The UML is a very important part of developing objects oriented software and the software \\ndevelopment process. The UML uses mostly graphical notations to express the design of software projects. \\n \\nInput data \\nPreprocessing \\nTraining dataset \\nFeature Extraction \\nPrediction/Classification \\n Testing Data \\nCrime types \\n24  \\nGOALS: \\n \\n The Primary goals in the design of the UML are as follows: \\n1. Provide users a ready -to-use, expressive visual modeling Language so that they can develop and \\nexchange meaningful models. \\n2. Provide extendibility and specialization mechanisms to extend the core concepts. \\n3. Be independent of particular programming languages and development process.'),\n",
       " Document(id='396e8506-9a90-4246-b240-f27c00bd0258', metadata={}, page_content='2  \\n \\nSATHYABAMA \\nINSTITUTE OF SCIENCE AND TECHNOLOGY \\n(DEEMED TO BE UNIVERSITY) \\nAccredited with Grade A by NAAC \\n(Established under Section 3 of UGC Act, 1956) \\nJEPPIAAR NAGAR, RAJIV GANDHI SALAI, CHENNAI 600119 \\nwww.sathyabamauniversity.ac.in \\n \\n \\nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\n \\n \\n                                               BONAFIDE CERTIFICATE \\n \\n \\nThis is to certify that this Project Report is the bonafide work of Avala Pavan  \\nKumar(38110058), Busupalli Harinath Reddy(38110063) who carried out the \\nproject entitled  A SYSTEMATIC APPROACH TOWARDS DESCRIPTION AND \\nCLASSIFICATION OF CRIME INCIDENTS  under my supervision from January \\n2022 to April 2022. \\n \\nInternal Guide \\n                            Dr. R. AROUL CANESSANE M.E., Ph.D., \\n \\n \\nHead of the Department \\n \\nDr. S.VIGNESHWARI, M.E., Ph.D., \\n \\n \\n \\n \\n \\nSubmitted for Viva voce Examination held on \\n \\n \\n \\n \\n \\nInternal Examiner External Examiner')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a990b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '\\n'.join([d.page_content for d in retrived_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e378149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.S.Vigneshwari M.E., Ph.D., and Dr.L.Lakshmanan M.E., Ph.D., Heads of the  \n",
      "Department of Computer Science and Engineering for providing me necessary \n",
      "support and details at the right time during the progressive reviews. \n",
      "I would like to express my sincere and deep sense of gratitude to my Project Guide  Dr. \n",
      "R. AROUL CANESSANE  M.E., Ph.D.,  for her valuable guidance, suggestions and  \n",
      "constant encouragement paved way for the successful completion of my project work. \n",
      "I wish to express my thanks to all Teaching and Non -teaching staff members of the  \n",
      "Department of Computer Science and Engineering who were helpful in many \n",
      "ways for the completion of the project.\n",
      "5  \n",
      " \n",
      "                                 TABLE OF CONTENT \n",
      " \n",
      "INDEX \n",
      "NO \n",
      "                                             TITLE PAGE \n",
      "NO \n",
      "1.                                 ABSTRACT 6 \n",
      "2. INTRODUCTION 7 \n",
      "3.                                     AIM 13 \n",
      "4.                                   SCOPE 13\n",
      "documenting the artifacts of software system, as well as for business modeling and other non -software \n",
      "systems.  \n",
      "The UML represents a collection of be st engineering practices that have proven successful in the \n",
      "modeling of large and complex systems. \n",
      " The UML is a very important part of developing objects oriented software and the software \n",
      "development process. The UML uses mostly graphical notations to express the design of software projects. \n",
      " \n",
      "Input data \n",
      "Preprocessing \n",
      "Training dataset \n",
      "Feature Extraction \n",
      "Prediction/Classification \n",
      " Testing Data \n",
      "Crime types \n",
      "24  \n",
      "GOALS: \n",
      " \n",
      " The Primary goals in the design of the UML are as follows: \n",
      "1. Provide users a ready -to-use, expressive visual modeling Language so that they can develop and \n",
      "exchange meaningful models. \n",
      "2. Provide extendibility and specialization mechanisms to extend the core concepts. \n",
      "3. Be independent of particular programming languages and development process.\n",
      "2  \n",
      " \n",
      "SATHYABAMA \n",
      "INSTITUTE OF SCIENCE AND TECHNOLOGY \n",
      "(DEEMED TO BE UNIVERSITY) \n",
      "Accredited with Grade A by NAAC \n",
      "(Established under Section 3 of UGC Act, 1956) \n",
      "JEPPIAAR NAGAR, RAJIV GANDHI SALAI, CHENNAI 600119 \n",
      "www.sathyabamauniversity.ac.in \n",
      " \n",
      " \n",
      "DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n",
      " \n",
      " \n",
      "                                               BONAFIDE CERTIFICATE \n",
      " \n",
      " \n",
      "This is to certify that this Project Report is the bonafide work of Avala Pavan  \n",
      "Kumar(38110058), Busupalli Harinath Reddy(38110063) who carried out the \n",
      "project entitled  A SYSTEMATIC APPROACH TOWARDS DESCRIPTION AND \n",
      "CLASSIFICATION OF CRIME INCIDENTS  under my supervision from January \n",
      "2022 to April 2022. \n",
      " \n",
      "Internal Guide \n",
      "                            Dr. R. AROUL CANESSANE M.E., Ph.D., \n",
      " \n",
      " \n",
      "Head of the Department \n",
      " \n",
      "Dr. S.VIGNESHWARI, M.E., Ph.D., \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Submitted for Viva voce Examination held on \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Internal Examiner External Examiner\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c598065",
   "metadata": {},
   "source": [
    "# Step 7: Augmenting (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111ac364",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_prompt = f'''\n",
    "<Role> You are helpful assistant using RAG.\n",
    "<Goal> Answer the question asked by the user. Here is the question: {prompt}\n",
    "<Context> Here are the documents retrieved from the vector database to support\n",
    "the answer which you have to generate {context}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e3f1c",
   "metadata": {},
   "source": [
    "# Step 8: Generation (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f567515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project, titled \"A SYSTEMATIC APPROACH TOWARDS DESCRIPTION AND CLASSIFICATION OF CRIME INCIDENTS\", focuses on using the Unified Modeling Language (UML) to develop object-oriented software. UML, a collection of best engineering practices, is crucial for modeling complex systems and software development processes, employing graphical notations for design expression. The project aims to provide an expressive visual modeling language for developing and exchanging meaningful models, with mechanisms for extensibility and specialization. It also emphasizes independence from specific programming languages and development processes. The core of the project involves input data preprocessing, feature extraction, and prediction/classification of crime types using a training dataset.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(augmented_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863aedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
